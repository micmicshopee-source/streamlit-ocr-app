import streamlit as st
import google.generativeai as genai
from PIL import Image, ImageEnhance
import pandas as pd
import json
import os
import io
import time
import base64
import requests
import altair as alt
import sqlite3
from datetime import datetime, timedelta

# --- 1. ç³»çµ±ä½ˆå±€èˆ‡åˆå§‹åŒ– ---
st.set_page_config(page_title="ç™¼ç¥¨å ±å¸³å°ç§˜ç¬ˆ", page_icon="ğŸ§¾", layout="wide")

if "db_error" not in st.session_state: st.session_state.db_error = None
if "db_path_mode" not in st.session_state: st.session_state.db_path_mode = "ğŸ’¾ æœ¬åœ°ç£ç¢Ÿ"

# --- 2. çµ‚æ¥µéŸŒæ€§è³‡æ–™åº«é€£ç·šå™¨ ---
def get_db_path():
    if "current_db_path" not in st.session_state:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        # æ”¹ç”¨ invoices_v2.db ä»¥è§£æ±ºèˆŠè³‡æ–™åº«å¯èƒ½ç™¼ç”Ÿçš„ Disk I/O Error é–å®šå•é¡Œ
        db_file = os.path.join(base_dir, "invoices_v2.db")
        try:
            # æ¸¬è©¦å¯«å…¥æ¬Šé™
            test_path = db_file + ".test"
            with open(test_path, "w") as f: f.write("1")
            os.remove(test_path)
            st.session_state.current_db_path = db_file
            st.session_state.db_path_mode = "ğŸ’¾ æœ¬åœ°ç£ç¢Ÿ"
        except:
            # å¤±æ•—å‰‡é€²å…¥å…±ç”¨è¨˜æ†¶é«”æ¨¡å¼
            st.session_state.current_db_path = "file:invoice_mem?mode=memory&cache=shared"
            st.session_state.db_path_mode = "ğŸ§  è™›æ“¬è¨˜æ†¶é«” (é‡å•Ÿæœƒæ¸…ç©º)"
    return st.session_state.current_db_path

def init_db():
    """åˆå§‹åŒ–è³‡æ–™è¡¨ï¼Œç¢ºä¿æ‰€æœ‰å¿…è¦æ¬„ä½å­˜åœ¨"""
    path = get_db_path()
    is_uri = "mode=memory" in path
    try:
        conn = sqlite3.connect(path, timeout=30, uri=is_uri)
        conn.execute('''CREATE TABLE IF NOT EXISTS invoices
                        (id INTEGER PRIMARY KEY AUTOINCREMENT, user_id TEXT DEFAULT 'default_user', 
                        file_name TEXT, date TEXT, invoice_number TEXT, seller_name TEXT, seller_ubn TEXT,
                        subtotal REAL, tax REAL, total REAL, category TEXT, subject TEXT, status TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')
        # è£œå…¨æ¬„ä½
        for col, c_type in {'user_id': "TEXT", 'status': "TEXT", 'seller_ubn': "TEXT"}.items():
            try: conn.execute(f"ALTER TABLE invoices ADD COLUMN {col} {c_type}")
            except: pass
        conn.commit()
        conn.close()
    except Exception as e:
        st.session_state.db_error = f"åˆå§‹åŒ–å¤±æ•—: {str(e)}"

def run_query(query, params=(), is_select=True):
    path = get_db_path()
    is_uri = "mode=memory" in path
    try:
        conn = sqlite3.connect(path, timeout=30, check_same_thread=False, uri=is_uri)
        if is_select:
            try:
                df = pd.read_sql_query(query, conn, params=params)
            except Exception as e:
                # é—œéµä¿®å¾©ï¼šå¦‚æœç™¼ç¾æ²’è¡¨ï¼Œè‡ªå‹•åˆå§‹åŒ–ä¸¦é‡è©¦
                if "no such table" in str(e):
                    init_db()
                    df = pd.read_sql_query(query, conn, params=params)
                else: raise e
            conn.close()
            st.session_state.db_error = None
            return df
        else:
            conn.execute(query, params)
            conn.commit()
            conn.close()
            return True
    except Exception as e:
        err_msg = str(e)
        st.session_state.db_error = f"é€£ç·šç•°å¸¸: {err_msg}"
        return pd.DataFrame() if is_select else False

# ç¨‹å¼å•Ÿå‹•ç«‹å³åˆå§‹åŒ–
init_db()

import re

# ... (ä¿æŒå‰é¢çš„ import ä¸å˜)

# --- 3. æ ¸å¿ƒè¾¨è­˜é‚è¼¯ ---
def extract_json(text):
    """å¾æ··åˆæ–‡æœ¬ä¸­æå–æœ‰æ•ˆçš„ JSON ç‰©ä»¶"""
    text = text.strip()
    # å˜—è©¦ 1: ç›´æ¥è§£æ
    try:
        return json.loads(text)
    except:
        pass
        
    # å˜—è©¦ 2: å°‹æ‰¾ Markdown ä»£ç¢¼å¡Š ```json ... ```
    match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        try: return json.loads(match.group(1))
        except: pass
        
    # å˜—è©¦ 3: å°‹æ‰¾æœ€å¤–å±¤çš„ {}
    match = re.search(r'(\{.*\})', text, re.DOTALL)
    if match:
        try: return json.loads(match.group(1))
        except: pass
        
    return None

def process_ocr(image_obj, file_name, model_name, api_key_val):
    try:
        if image_obj.mode != "RGB": image_obj = image_obj.convert("RGB")
        # ç¨å¾®é™ä½è§£æåº¦ä»¥åŠ å¿«é€Ÿåº¦ä¸¦æ¸›å°‘ Tokenï¼Œä½†ä¿æŒè¶³å¤ æ¸…æ™°åº¦
        image_obj.thumbnail((1600, 1600), Image.Resampling.LANCZOS)
        img_byte = io.BytesIO(); image_obj.save(img_byte, format="JPEG", quality=85)
        img_base64 = base64.b64encode(img_byte.getvalue()).decode()
        
        # å„ªåŒ– Promptï¼šæ˜ç¢ºè¦æ±‚ç´” JSONï¼Œä¸è¦ Markdown
        prompt = """You are a receipt OCR assistant. Extract data from this image.
        Output ONLY a valid JSON object. Do NOT use Markdown code blocks.
        Fields required:
        - date (Format: YYYY/MM/DD, convert ROC year to AD if needed)
        - invoice_no (Invoice number)
        - seller_name (Store name)
        - seller_ubn (Unified Business Number / Tax ID)
        - subtotal (Amount before tax, number only)
        - tax (Tax amount, number only)
        - total (Total amount, number only)
        - type (Invoice type, e.g., "é›»å­ç™¼ç¥¨", "æ”¶æ“š")
        - category_suggest (Category, e.g., "é¤é£²", "äº¤é€š", "è¾¦å…¬ç”¨å“")
        
        If a field is missing, use null or 0.
        """
        
        payload = {
            "contents": [{"parts": [{"text": prompt}, {"inline_data": {"mime_type": "image/jpeg", "data": img_base64}}]}], 
            "generationConfig": {"temperature": 0.1, "maxOutputTokens": 1024}
        }
        
        # å„ªå…ˆé †åºèª¿æ•´ï¼šå…ˆè©¦ v1beta (æ”¯æ´è¼ƒæ–°æ¨¡å‹)ï¼Œå†è©¦ v1
        configs = [
            ("v1beta", model_name),
            ("v1beta", f"models/{model_name}"),
            ("v1", model_name),
            ("v1", f"models/{model_name}")
        ]
        
        session = requests.Session(); session.trust_env = False
        os.environ.pop('HTTP_PROXY', None); os.environ.pop('HTTPS_PROXY', None)
        
        last_err = ""
        debug_info = []
        
        for ver, m_name in configs:
            # æ™ºèƒ½è™•ç† models/ å‰ç¶´
            final_model_name = m_name if "models/" in m_name else f"models/{m_name}"
            # ä¿®æ­£ URL çµæ§‹ï¼šv1beta/models/gemini-pro:generateContent
            # ç§»é™¤å¤šé¤˜çš„ models/ å¦‚æœ API ç‰ˆæœ¬è·¯å¾‘å·²ç¶“éš±å«
            if ver == "v1beta" or ver == "v1":
                 # Google API è¦ç¯„: https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent
                 # å¦‚æœ m_name å·²ç¶“åŒ…å« models/ï¼Œå‰‡ç›´æ¥ä½¿ç”¨
                 pass

            url = f"https://generativelanguage.googleapis.com/{ver}/{m_name}:generateContent?key={api_key_val}"
            if "models/" not in m_name:
                 url = f"https://generativelanguage.googleapis.com/{ver}/models/{m_name}:generateContent?key={api_key_val}"
            
            try:
                resp = session.post(url, json=payload, timeout=25)
                if resp.status_code == 200:
                    try:
                        resp_json = resp.json()
                        if 'candidates' not in resp_json or not resp_json['candidates']:
                            last_err = "API å›å‚³çµæ§‹ç•°å¸¸ (ç„¡ candidates)"
                            continue
                            
                        text = resp_json['candidates'][0]['content']['parts'][0]['text']
                        raw = extract_json(text)
                        
                        if raw:
                            data = {
                                "file_name": file_name,
                                "date": raw.get("date") or raw.get("æ—¥æœŸ") or datetime.now().strftime("%Y/%m/%d"),
                                "invoice_no": raw.get("invoice_no") or raw.get("invoice_number") or "N/A",
                                "seller_name": raw.get("seller_name") or "N/A",
                                "seller_ubn": raw.get("seller_ubn") or "N/A",
                                "subtotal": raw.get("subtotal") or 0, "tax": raw.get("tax") or 0, "total": raw.get("total") or 0,
                                "type": raw.get("type") or "å…¶ä»–", "category_suggest": raw.get("category_suggest") or "é›œé …"
                            }
                            data["status"] = "âœ… æ­£å¸¸" if data["total"] else "âš ï¸ ç¼ºæ¼"
                            return data, None
                        else:
                            last_err = f"JSON è§£æå¤±æ•—. åŸå§‹æ–‡æœ¬: {text[:100]}..."
                            debug_info.append(f"{ver}/{m_name}: {last_err}")
                    except Exception as parse_err:
                        last_err = f"è§£æç•°å¸¸: {str(parse_err)}"
                        debug_info.append(f"{ver}/{m_name}: {last_err}")
                else:
                    last_err = f"HTTP {resp.status_code}: {resp.text[:100]}"
                    debug_info.append(f"{ver}/{m_name}: {last_err}")
            except Exception as e: 
                last_err = str(e)
                debug_info.append(f"{ver}/{m_name}: {last_err}")
                continue
                
        return None, f"æ‰€æœ‰å˜—è©¦çš†å¤±æ•—ã€‚æœ€å¾ŒéŒ¯èª¤: {last_err} | æ­·ç¨‹: {'; '.join(debug_info)}"
    except Exception as e: return None, f"ç³»çµ±éŒ¯èª¤: {str(e)}"

# --- 4. ä»‹é¢æ¸²æŸ“ ---
DEFAULT_KEY = "AIzaSyBe4HixC1ImmO5NtJnhjrCKl62J0_ntUGQ"

with st.sidebar:
    st.title("âš™ï¸ ç³»çµ±ç‹€æ…‹")
    user = st.text_input("ç™»å…¥å¸³è™Ÿ", "default_user")
    
    # å„ªå…ˆä½¿ç”¨ Streamlit Secrets
    if "GEMINI_API_KEY" in st.secrets:
        st.success("ğŸ”‘ å·²ä½¿ç”¨ Secrets é‡‘é‘°")
        api_key = st.secrets["GEMINI_API_KEY"]
    else:
        api_key = st.text_input("Gemini API Key", DEFAULT_KEY, type="password")
        st.caption("å»ºè­°åœ¨ Streamlit Secrets è¨­å®š GEMINI_API_KEY")

    model = st.selectbox("è¾¨è­˜æ¨¡å‹", ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-1.5-flash", "gemini-1.5-pro"])
    
    st.divider()
    # é€™è£¡æœƒè§¸ç™¼ run_queryï¼Œè‹¥æ²’è¡¨æœƒè‡ªå‹•å»ºè¡¨
    db_count_df = run_query("SELECT count(*) as count FROM invoices WHERE user_id = ?", (user,))
    if not db_count_df.empty:
        st.success(f"ğŸ“Š å·²å­˜æ•¸æ“š: {db_count_df['count'][0]} ç­†")
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæš«å­˜è³‡æ–™åº«"):
        try:
            os.remove("invoices.db")
            st.success("å·²æ¸…é™¤ï¼")
            time.sleep(1)
            st.rerun()
        except: pass


st.title("ğŸ“‘ ç™¼ç¥¨æ”¶æ“šå ±å¸³å°ç§˜ç¬ˆ Pro")
col_up, col_main, col_stat = st.columns([1, 2.5, 1])

with col_up:
    st.subheader("ğŸ“¤ ä¸Šå‚³è¾¨è­˜")
    files = st.file_uploader("æ‰¹æ¬¡é¸æ“‡ç…§ç‰‡", type=["jpg","png","jpeg"], accept_multiple_files=True)
    if files and st.button("é–‹å§‹è¾¨è­˜ ğŸš€", type="primary", use_container_width=True):
        
        # åˆå§‹åŒ– session_state ç”¨æ–¼å­˜å„²çµæœå ±å‘Šï¼ˆå¦‚æœé‚„æ²’æœ‰çš„è©±ï¼‰
        if "ocr_report" not in st.session_state: st.session_state.ocr_report = []
        
        success_count = 0
        fail_count = 0
        
        with st.status("AI æ­£åœ¨åˆ†æç™¼ç¥¨ä¸­...", expanded=True) as status:
            prog = st.progress(0)
            
            for idx, f in enumerate(files):
                st.write(f"æ­£åœ¨è™•ç†: {f.name} ...")
                data, err = process_ocr(Image.open(f), f.name, model, api_key)
                
                if data:
                    def clean_n(v):
                        try: return float(str(v).replace(',','').replace('$',''))
                        except: return 0.0
                    q = "INSERT INTO invoices (user_id, file_name, date, invoice_number, seller_name, seller_ubn, subtotal, tax, total, category, subject, status) VALUES (?,?,?,?,?,?,?,?,?,?,?,?)"
                    run_query(q, (user, data["file_name"], data["date"], data["invoice_no"], data["seller_name"], data["seller_ubn"], 
                                clean_n(data["subtotal"]), clean_n(data["tax"]), clean_n(data["total"]), data["type"], data["category_suggest"], data["status"]), is_select=False)
                    st.write(f"âœ… {f.name}: æˆåŠŸ (${data.get('total', 0)})")
                    success_count += 1
                else:
                    st.error(f"âŒ {f.name} å¤±æ•—: {err}")
                    st.session_state.ocr_report.append(f"{f.name}: {err}")
                    fail_count += 1
                
                prog.progress((idx+1)/len(files))
            
            status.update(label=f"è™•ç†å®Œæˆ! æˆåŠŸ: {success_count}, å¤±æ•—: {fail_count}", state="complete", expanded=True)
            
        if success_count > 0:
            time.sleep(1) # è®“ä½¿ç”¨è€…ç¨å¾®çœ‹ä¸€ä¸‹çµæœ
            st.rerun()

with col_main:
    sc1, sc2 = st.columns([2, 1])
    search = sc1.text_input("ğŸ” é—œéµå­—æœå°‹", placeholder="è™Ÿç¢¼/è³£æ–¹/æª”å...")
    t_filter = sc2.selectbox("ğŸ•’ æ™‚é–“ç¯„åœ", ["å…¨éƒ¨", "ä»Šå¤©", "æœ¬é€±", "æœ¬æœˆ"])
    
    df = run_query("SELECT * FROM invoices WHERE user_id = ? ORDER BY id DESC", (user,))
    # æ‰‹å‹•åœ¨è¨˜æ†¶é«”ä¸­ç¯©é¸ï¼ˆé¿å… SQL éæ–¼è¤‡é›œå‡ºéŒ¯ï¼‰
    if not df.empty:
        if search:
            df = df[df.apply(lambda row: search.lower() in str(row).lower(), axis=1)]
        if t_filter != "å…¨éƒ¨":
            # ç°¡å–®æ—¥æœŸéæ¿¾
            pass 
        
        st.subheader("ğŸ“‹ æ•¸æ“šç¨½æ ¸å ±è¡¨")
        if not df.empty:
            mapping = {"file_name":"æª”æ¡ˆåç¨±","date":"æ—¥æœŸ","invoice_number":"ç™¼ç¥¨è™Ÿç¢¼","seller_name":"è³£æ–¹åç¨±","seller_ubn":"è³£æ–¹çµ±ç·¨","subtotal":"éŠ·å”®é¡","tax":"ç¨…é¡","total":"ç¸½è¨ˆ","category":"é¡å‹","subject":"æœƒè¨ˆç§‘ç›®","status":"ç‹€æ…‹"}
            df = df.rename(columns=mapping)
            if "é¸å–" not in df.columns: df.insert(0, "é¸å–", False)
            
            if st.button("ğŸ—‘ï¸ åˆªé™¤é¸ä¸­æ•¸æ“š"):
                ids = df[df["é¸å–"]==True]["id"].tolist()
                for i in ids: run_query("DELETE FROM invoices WHERE id=?", (i,), is_select=False)
                st.rerun()
            
            ed_df = st.data_editor(df, use_container_width=True, hide_index=True, height=500, 
                                   column_config={"id": None, "é¸å–": st.column_config.CheckboxColumn("é¸å–", default=False)})
            df["é¸å–"] = ed_df["é¸å–"]
        else: st.warning("âš ï¸ æŸ¥ç„¡æ•¸æ“šã€‚")
    else: st.warning("âš ï¸ ç›®å‰ç„¡æ•¸æ“šã€‚è«‹å…ˆå˜—è©¦ä¸Šå‚³ä¸¦è¾¨è­˜ã€‚")

with col_stat:
    st.subheader("ğŸ“Š çµ±è¨ˆå ±è¡¨")
    if not df.empty and "ç¸½è¨ˆ" in df.columns:
        for c in ["ç¸½è¨ˆ", "ç¨…é¡"]: df[c] = pd.to_numeric(df[c].astype(str).str.replace(',',''), errors='coerce').fillna(0)
        m1, m2 = st.columns(2)
        m1.metric("ç´¯è¨ˆé‡‘é¡", f"${df['ç¸½è¨ˆ'].sum():,.0f}")
        m2.metric("ç´¯è¨ˆç¨…é¡", f"${df['ç¨…é¡'].sum():,.0f}")
        st.divider()
        st.download_button("ğŸ“¥ å°å‡º CSV", df.to_csv(index=False).encode('utf-8-sig'), "invoice_report.csv", use_container_width=True)
        chart = alt.Chart(df).mark_arc(innerRadius=40).encode(theta="count()", color="é¡å‹", tooltip=["é¡å‹", "count()"]).properties(height=200)
        st.altair_chart(chart, use_container_width=True)
